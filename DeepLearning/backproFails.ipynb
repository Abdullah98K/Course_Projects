{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "Python 3.8.1 64-bit",
      "display_name": "Python 3.8.1 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
        }
      }
    },
    "colab": {
      "name": "backproFails.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "source": [
        "# <center>Bonus Problem</center>\n",
        "## <center>Backprop Fails to Separate where Perceptron Succeeds</center>\n",
        "### Authors\n",
        "#### Ibrahim Alzekri 201616860\n",
        "#### Abdullah Alkhalifah 201690090\n",
        "In this notebook we will proof that in some cases, backpropagation fails to seperate all points. Whereas a single perceptron succeeds to sepearate the points perfectly\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "fyvTaywcpJ5Z",
        "outputId": "9615d03e-85f3-4677-cecd-f7e2e267c568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data.dataloader as dataloader\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "%matplotlib inline\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6.0\n"
          ]
        }
      ]
    },
    {
      "source": [
        "### i. Sampling\n",
        "Here, we are going to generate n random points with a shape similar to the following dataset\n",
        "\n",
        "<img src=\"backFailsDist.png\" style=\"max-width: 300px;\" />\n",
        "\n",
        "\n",
        "Then, we will add some noise that our perceptron will be able to seperate, while the backpropagation will fail."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5CyzgaSpJ5r"
      },
      "source": [
        "def sample_points(n):\n",
        "    # returns (X,Y), where X of shape (n,2) is the numpy array of points and Y is the (n) array of classes\n",
        "\n",
        "    set_size = int(n/3)\n",
        "    #Set 1\n",
        "    x1_a = np.random.uniform(low= 2 , high= 3, size= set_size).reshape(-1,1)\n",
        "    x2_a = np.random.uniform(low= -0.3 , high= 0.3, size= set_size).reshape(-1,1)\n",
        "    x = np.concatenate([x1_a,x2_a],axis=1)\n",
        "    \n",
        "    #set 2\n",
        "    x1_b = np.random.uniform(low= -0.3 , high= 0.3, size= set_size).reshape(-1,1)\n",
        "    x2_b = np.random.uniform(low= 2 , high= 3, size= set_size).reshape(-1,1)\n",
        "    x = np.append(x, np.concatenate([x1_b,x2_b],axis=1), axis=0 ) \n",
        "    \n",
        "    #set 3\n",
        "    x1_c = np.random.uniform(low= -3 , high= -2, size= set_size).reshape(-1,1)\n",
        "    x2_c = np.random.uniform(low= -0.3 , high= 0.3, size= set_size).reshape(-1,1)\n",
        "    x = np.append(x, np.concatenate([x1_c,x2_c],axis=1), axis=0 ) \n",
        "\n",
        "    y = np.zeros( (1, 2*set_size) )\n",
        "    y = np.append(y, np.ones((1, set_size)) )\n",
        "\n",
        "    #noise\n",
        "    n_size = int(n/30)\n",
        "    x1_n = np.random.uniform(low= -1 , high= -0.8, size= n_size).reshape(-1,1)\n",
        "    x2_n = np.random.uniform(low= -1 , high= -0.8, size= n_size).reshape(-1,1)\n",
        "    x = np.append(x, np.concatenate([x1_n,x2_n],axis=1), axis=0 ) \n",
        "    y = np.append(y, np.zeros((1, n_size)) )\n",
        "    \n",
        "    return x,y"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44vsWnbppJ5f"
      },
      "source": [
        "### ii. Designing a Single Perceptron with defined parameters\n",
        "Here is our single perceptron with parameters: w1 = -2.5, w2 = -1, b = -4. And a simple step functon as activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLoeAd1wpJ5g"
      },
      "source": [
        "class perceptron(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # initialize layers\n",
        "        self.layer1 = nn.Linear(2, 1)\n",
        "        self.intialize_params()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # make sure the input tensor is flattened\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        output = self.step(self.layer1(x))\n",
        "\n",
        "        return output\n",
        "    \n",
        "    def intialize_params(self):        \n",
        "        \n",
        "        \n",
        "        old_params = {}\n",
        "\n",
        "        for name, params in self.named_parameters():\n",
        "            old_params[name] = params.clone()\n",
        "\n",
        "\n",
        "        old_params['layer1.weight'] = [-2.5 , -1]                \n",
        "        old_params['layer1.bias'] = [-4]\n",
        "\n",
        "\n",
        "        for name, params in self.named_parameters():\n",
        "            params.data.copy_(torch.tensor(old_params[name]))\n",
        "\n",
        "\n",
        "    def step (self, x):\n",
        "        return (x>=0)*1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFoq8Cl6pJ5k"
      },
      "source": [
        "### iii. Designing a Single Perceptron with backpropagation implementation\n",
        "Here is our backpropagation model. Which is a single perceptron with backpropagation implementation and ReLU as an activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIwVIkJOpJ5l"
      },
      "source": [
        "class backpropagation(nn.Module):\n",
        "    \n",
        "\n",
        "  def __init__(self): \n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Linear(2,2)\n",
        "    self.act = nn.ReLU()\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.layer1(x)\n",
        "    return self.act(x)\n",
        "    \n",
        "  def train_net(self,x,y,n_iters):\n",
        "\n",
        "    train_data = x\n",
        "    train_labels = y\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(self.parameters(),lr=0.01)\n",
        "\n",
        "    for epoch in range(n_iters):\n",
        "      #zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      #compute foward, backward and optimize\n",
        "      output = self(train_data)\n",
        "      loss = criterion(output,train_labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if epoch%100==99: # every 500 iterations, print statistics\n",
        "          print(\"epoch #: \",epoch+1)\n",
        "          # accuracy of the train prediction\n",
        "          train_prediction = output.cpu().detach().argmax(dim=1)\n",
        "          train_accuracy = (train_prediction.numpy()==train_labels.cpu().detach().numpy()).mean()\n",
        "\n",
        "          print(\"Training loss :\",loss.cpu().detach().numpy())\n",
        "          print(\"Training accuracy :\",train_accuracy)\n",
        "          print('='*20)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy01gzCRpJ5o"
      },
      "source": [
        "### iv. Plotting\n",
        "Thie method is to plot the dataset with two seperators. One found by the single perceptron model, and the other produced by the backpropagation model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9Sxb2d1pJ5o"
      },
      "source": [
        "def compare_models(net1, net2, x, y):\n",
        "\n",
        "# Getting true and false points\n",
        "  green = x.numpy()[np.where(y==1)[0]]\n",
        "  red = x.numpy()[np.where(y==0)[0]]\n",
        "\n",
        "# Getting models weights and biasses to draw seperator lines\n",
        "  model1_params = {}\n",
        "  \n",
        "  for name, params in net1.named_parameters():\n",
        "      model1_params[name] = params.clone()\n",
        "\n",
        "  model2_params = {}\n",
        "  \n",
        "  for name, params in net2.named_parameters():\n",
        "      model2_params[name] = params.clone()\n",
        "\n",
        "  m1_w = model1_params['layer1.weight'][0].detach().numpy()\n",
        "  m1_b = model1_params['layer1.bias'][0].detach().numpy()\n",
        "\n",
        "  m2_w = model2_params['layer1.weight'][0].detach().numpy()\n",
        "  m2_b = model2_params['layer1.bias'][0].detach().numpy()\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "\n",
        "  plt.xlim((-5,5))\n",
        "  plt.ylim((-5,5))\n",
        "\n",
        "  # Slope and bias of the function\n",
        "  m = -(m1_w[0]/m1_w[1])\n",
        "  b = -(m1_b/m1_w[1])\n",
        "  plt.plot(x, m*x + b , linestyle='-', color='b')  # solid\n",
        "\n",
        "  m = -(m2_w[0]/m2_w[1])\n",
        "  b = -(m2_b/m2_w[1])\n",
        "  plt.plot(x, m*x + b, linestyle='--',  color='r') # dashed\n",
        "\n",
        "  pos_values = plt.scatter(x=green[:,0],y=green[:,1], color='g',)\n",
        "  neg_values = plt.scatter(x=red[:,0],y=red[:,1], color='r',)\n",
        "\n",
        "  ax.add_artist(pos_values)\n",
        "  ax.add_artist(neg_values)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "source": [
        "### v. Creating and training models\n",
        "We will creaete sample points with n = 30, similar to the shape proposed in the begining. Then, we will create the two models and train the backpropagation model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "1h-j801gpJ5y",
        "outputId": "ec913b0b-1a98-43d8-e2d5-d858fd2e84a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x, y = sample_points(30)\n",
        "x = torch.from_numpy(x).float() # data points\n",
        "y = torch.from_numpy(y).long() # labels\n",
        "\n",
        "perceptron_model = perceptron()\n",
        "backpro_model = backpropagation()\n",
        "backpro_model.train_net(x,y,500)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch #:  100\n",
            "Training loss : 0.23891088\n",
            "Training accuracy : 1.0\n",
            "====================\n",
            "epoch #:  200\n",
            "Training loss : 0.17585386\n",
            "Training accuracy : 0.967741935483871\n",
            "====================\n",
            "epoch #:  300\n",
            "Training loss : 0.14220333\n",
            "Training accuracy : 0.967741935483871\n",
            "====================\n",
            "epoch #:  400\n",
            "Training loss : 0.121664345\n",
            "Training accuracy : 0.967741935483871\n",
            "====================\n",
            "epoch #:  500\n",
            "Training loss : 0.10806042\n",
            "Training accuracy : 0.967741935483871\n",
            "====================\n"
          ]
        }
      ]
    },
    {
      "source": [
        "### vi. Printing Models and Seperators\n",
        "The **blue** line is produced by the **single perceptron** model. And the **red** line is produced by the **backprooagation** model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "QXto0Z0gpJ51",
        "outputId": "356501a0-dc48-4a23-c3f6-aaa96ca43661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "compare_models(perceptron_model, backpro_model, x, y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 370.942187 248.518125\" width=\"370.942187pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 370.942187 248.518125 \nL 370.942187 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 28.942188 224.64 \nL 363.742188 224.64 \nL 363.742188 7.2 \nL 28.942188 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"mf94e8d4695\" style=\"stroke:#008000;\"/>\n    </defs>\n    <g clip-path=\"url(#pd4da31e432)\">\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"99.834709\" xlink:href=\"#mf94e8d4695\" y=\"118.71648\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"96.544783\" xlink:href=\"#mf94e8d4695\" y=\"109.795494\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"109.275768\" xlink:href=\"#mf94e8d4695\" y=\"111.297559\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"103.861085\" xlink:href=\"#mf94e8d4695\" y=\"110.243026\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"114.828112\" xlink:href=\"#mf94e8d4695\" y=\"114.59972\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"116.952756\" xlink:href=\"#mf94e8d4695\" y=\"116.396058\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"115.607419\" xlink:href=\"#mf94e8d4695\" y=\"118.493015\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"120.976802\" xlink:href=\"#mf94e8d4695\" y=\"114.809009\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"107.068419\" xlink:href=\"#mf94e8d4695\" y=\"110.453899\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"101.177268\" xlink:href=\"#mf94e8d4695\" y=\"110.203712\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_2\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"mdf656d662a\" style=\"stroke:#ff0000;\"/>\n    </defs>\n    <g clip-path=\"url(#pd4da31e432)\">\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"286.12959\" xlink:href=\"#mdf656d662a\" y=\"115.651288\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"270.450647\" xlink:href=\"#mdf656d662a\" y=\"111.01218\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"278.498364\" xlink:href=\"#mdf656d662a\" y=\"120.532354\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"273.356922\" xlink:href=\"#mdf656d662a\" y=\"117.227229\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"287.888105\" xlink:href=\"#mdf656d662a\" y=\"120.017766\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"281.266649\" xlink:href=\"#mdf656d662a\" y=\"121.516243\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"270.654594\" xlink:href=\"#mdf656d662a\" y=\"120.342876\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"264.903771\" xlink:href=\"#mdf656d662a\" y=\"109.733144\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"285.5204\" xlink:href=\"#mdf656d662a\" y=\"116.919029\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"292.952909\" xlink:href=\"#mdf656d662a\" y=\"112.157518\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"192.406575\" xlink:href=\"#mdf656d662a\" y=\"66.129896\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"193.95343\" xlink:href=\"#mdf656d662a\" y=\"63.738659\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"193.629508\" xlink:href=\"#mdf656d662a\" y=\"64.974146\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"186.562242\" xlink:href=\"#mdf656d662a\" y=\"66.638349\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"202.166202\" xlink:href=\"#mdf656d662a\" y=\"69.900667\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"187.618967\" xlink:href=\"#mdf656d662a\" y=\"69.377697\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"191.818403\" xlink:href=\"#mdf656d662a\" y=\"50.846532\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"191.636269\" xlink:href=\"#mdf656d662a\" y=\"55.787905\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"199.80295\" xlink:href=\"#mdf656d662a\" y=\"54.543299\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"205.279804\" xlink:href=\"#mdf656d662a\" y=\"64.685632\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"163.011819\" xlink:href=\"#mdf656d662a\" y=\"133.874541\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_3\">\n    <g clip-path=\"url(#pd4da31e432)\">\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"99.834709\" xlink:href=\"#mf94e8d4695\" y=\"118.71648\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"96.544783\" xlink:href=\"#mf94e8d4695\" y=\"109.795494\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"109.275768\" xlink:href=\"#mf94e8d4695\" y=\"111.297559\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"103.861085\" xlink:href=\"#mf94e8d4695\" y=\"110.243026\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"114.828112\" xlink:href=\"#mf94e8d4695\" y=\"114.59972\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"116.952756\" xlink:href=\"#mf94e8d4695\" y=\"116.396058\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"115.607419\" xlink:href=\"#mf94e8d4695\" y=\"118.493015\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"120.976802\" xlink:href=\"#mf94e8d4695\" y=\"114.809009\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"107.068419\" xlink:href=\"#mf94e8d4695\" y=\"110.453899\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"101.177268\" xlink:href=\"#mf94e8d4695\" y=\"110.203712\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_4\">\n    <g clip-path=\"url(#pd4da31e432)\">\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"286.12959\" xlink:href=\"#mdf656d662a\" y=\"115.651288\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"270.450647\" xlink:href=\"#mdf656d662a\" y=\"111.01218\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"278.498364\" xlink:href=\"#mdf656d662a\" y=\"120.532354\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"273.356922\" xlink:href=\"#mdf656d662a\" y=\"117.227229\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"287.888105\" xlink:href=\"#mdf656d662a\" y=\"120.017766\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"281.266649\" xlink:href=\"#mdf656d662a\" y=\"121.516243\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"270.654594\" xlink:href=\"#mdf656d662a\" y=\"120.342876\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"264.903771\" xlink:href=\"#mdf656d662a\" y=\"109.733144\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"285.5204\" xlink:href=\"#mdf656d662a\" y=\"116.919029\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"292.952909\" xlink:href=\"#mdf656d662a\" y=\"112.157518\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"192.406575\" xlink:href=\"#mdf656d662a\" y=\"66.129896\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"193.95343\" xlink:href=\"#mdf656d662a\" y=\"63.738659\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"193.629508\" xlink:href=\"#mdf656d662a\" y=\"64.974146\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"186.562242\" xlink:href=\"#mdf656d662a\" y=\"66.638349\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"202.166202\" xlink:href=\"#mdf656d662a\" y=\"69.900667\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"187.618967\" xlink:href=\"#mdf656d662a\" y=\"69.377697\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"191.818403\" xlink:href=\"#mdf656d662a\" y=\"50.846532\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"191.636269\" xlink:href=\"#mdf656d662a\" y=\"55.787905\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"199.80295\" xlink:href=\"#mdf656d662a\" y=\"54.543299\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"205.279804\" xlink:href=\"#mdf656d662a\" y=\"64.685632\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"163.011819\" xlink:href=\"#mdf656d662a\" y=\"133.874541\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mc1c1f05b5c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.422188\" xlink:href=\"#mc1c1f05b5c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −4 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(55.051094 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"129.382188\" xlink:href=\"#mc1c1f05b5c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(122.011094 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"196.342188\" xlink:href=\"#mc1c1f05b5c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(193.160938 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"263.302188\" xlink:href=\"#mc1c1f05b5c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2 -->\n      <g transform=\"translate(260.120938 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"330.262188\" xlink:href=\"#mc1c1f05b5c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 4 -->\n      <g transform=\"translate(327.080938 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m3efce8bc81\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.942188\" xlink:href=\"#m3efce8bc81\" y=\"202.896\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- −4 -->\n      <g transform=\"translate(7.2 206.695219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.942188\" xlink:href=\"#m3efce8bc81\" y=\"159.408\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- −2 -->\n      <g transform=\"translate(7.2 163.207219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.942188\" xlink:href=\"#m3efce8bc81\" y=\"115.92\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g transform=\"translate(15.579688 119.719219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.942188\" xlink:href=\"#m3efce8bc81\" y=\"72.432\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 2 -->\n      <g transform=\"translate(15.579688 76.231219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.942188\" xlink:href=\"#m3efce8bc81\" y=\"28.944\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 4 -->\n      <g transform=\"translate(15.579688 32.743219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_11\">\n    <path clip-path=\"url(#pd4da31e432)\" d=\"M 225.056478 249.518125 \nL 192.406575 196.50592 \nL 193.95343 199.017481 \nL 193.629508 198.491542 \nL 186.562242 187.016731 \nL 202.166202 212.352192 \nL 187.618967 188.73249 \nL 191.818403 195.550928 \nL 191.636269 195.255207 \nL 199.80295 208.515084 \nL 205.279804 217.407611 \nL 99.834709 46.201056 \nL 96.544783 40.859356 \nL 109.275768 61.530098 \nL 103.861085 52.738507 \nL 114.828112 70.545189 \nL 116.952756 73.994883 \nL 115.607419 71.810521 \nL 120.976802 80.528549 \nL 107.068419 57.946113 \nL 101.177268 48.380918 \nL 163.011819 148.778951 \n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#pd4da31e432)\" d=\"M 196.755932 203.567776 \nL 203.89893 215.16555 \nL 189.240384 191.365112 \nL 194.329401 199.627928 \nL 190.032714 192.651586 \nL 187.725455 188.905393 \nL 189.53213 191.838811 \nL 205.868306 218.363137 \nL 194.803948 200.398426 \nL 202.135414 212.302206 \nL 225.056476 249.518125 \nM 225.056478 249.518125 \nL 192.03635 195.9048 \nL 205.772305 218.20727 \nL 203.459522 214.452104 \nL 205.083224 217.088432 \nL 198.37507 206.196701 \nL 195.609184 201.705854 \nL 192.380426 196.463462 \nL 198.052819 205.673473 \nL 204.758534 216.561253 \nL 205.143756 217.186714 \nL 168.69695 158.009647 \n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path clip-path=\"url(#pd4da31e432)\" d=\"M 286.12959 215.522801 \nL 270.450647 204.175713 \nL 278.498364 209.999966 \nL 273.356922 206.279026 \nL 287.888105 216.795464 \nL 281.266649 212.003421 \nL 270.654594 204.323307 \nL 264.903771 200.161348 \nL 285.5204 215.081918 \nL 292.952909 220.460944 \nL 192.406575 147.694002 \nL 193.95343 148.813485 \nL 193.629508 148.57906 \nL 186.562242 143.46437 \nL 202.166202 154.757198 \nL 187.618967 144.229136 \nL 191.818403 147.268335 \nL 191.636269 147.136522 \nL 199.80295 153.046874 \nL 205.279804 157.010558 \nL 99.834709 80.698307 \nL 96.544783 78.317336 \nL 109.275768 87.53095 \nL 103.861085 83.612259 \nL 114.828112 91.549265 \nL 116.952756 93.086906 \nL 115.607419 92.113261 \nL 120.976802 95.999168 \nL 107.068419 85.933457 \nL 101.177268 81.669941 \nL 163.011819 126.420562 \n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#pd4da31e432)\" d=\"M 196.755932 150.8417 \nL 203.89893 156.0112 \nL 189.240384 145.402582 \nL 194.329401 149.085582 \nL 190.032714 145.976003 \nL 187.725455 144.306204 \nL 189.53213 145.613723 \nL 205.868306 157.436467 \nL 194.803948 149.429021 \nL 202.135414 154.734916 \nL 273.005759 206.024887 \nL 276.687629 208.689511 \nL 274.785306 207.312771 \nL 272.222875 205.458299 \nL 267.19977 201.823 \nL 268.005004 202.405764 \nL 296.53809 223.055592 \nL 288.929685 217.549274 \nL 290.846049 218.936175 \nL 275.229543 207.634272 \nL 192.03635 147.426066 \nL 205.772305 157.366991 \nL 203.459522 155.693192 \nL 205.083224 156.868292 \nL 198.37507 152.013497 \nL 195.609184 150.011781 \nL 192.380426 147.67508 \nL 198.052819 151.780279 \nL 204.758534 156.633308 \nL 205.143756 156.9121 \nL 168.69695 130.53498 \n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 28.942188 224.64 \nL 28.942188 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 363.742188 224.64 \nL 363.742188 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 28.942187 224.64 \nL 363.742188 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 28.942187 7.2 \nL 363.742188 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pd4da31e432\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"28.942188\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "source": [
        "### vii. Results\n",
        "As we can see, though the backpropagation model has converged. It still fails to seperate all points correctly. On the other hand, the single perceptron model succeeded to seperate all points correctly"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "vOAaOFQgpJ53"
      }
    }
  ]
}